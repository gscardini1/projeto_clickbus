# dashboard_clickbus.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
from sklearn.model_selection import train_test_split

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Dashboard de Modelos Preditivos - ClickBus",
    page_icon="üöå",
    layout="wide"
)

# --- Fun√ß√µes de Cache para Carregamento de Dados ---
# O cache acelera o carregamento do dashboard ao n√£o recarregar os dados a cada intera√ß√£o.
@st.cache_data
def load_data(file_path):
    return pd.read_csv(file_path)

@st.cache_data
def process_main_data(df):
    df['datetime_purchase'] = pd.to_datetime(df['date_purchase'] + ' ' + df['time_purchase'])
    df['route'] = df['place_origin_departure'] + ' -> ' + df['place_destination_departure']
    return df

# --- Carregamento dos Dados ---
try:
    df_raw = load_data('df_t.csv')
    df_segmented = load_data('clientes_segmentados_rfm.csv')
    df_processed = process_main_data(df_raw.copy())
except FileNotFoundError:
    st.error("Erro: Arquivos 'df_t.csv' ou 'clientes_segmentados_rfm.csv' n√£o encontrados. Por favor, coloque-os na mesma pasta do script.")
    st.stop()

# Cria a coluna 'target_route' para o modelo de previs√£o de pr√≥xima rota
top_routes_global = df_processed['route'].value_counts().nlargest(50).index.tolist()
df_processed['target_route'] = df_processed['route'].apply(lambda x: x if x in top_routes_global else 'Outra')

# --- T√≠tulo do Dashboard ---
st.title("üöå Dashboard de Modelos de Dados - An√°lise de Clientes ClickBus")
st.markdown("Este dashboard apresenta os resultados dos tr√™s principais desafios de modelagem de dados.")

# --- Cria√ß√£o das Abas ---
tab1, tab2, tab3 = st.tabs([
    "üéØ **1. Segmenta√ß√£o de Clientes (K-Means)**",
    "üìà **2. Previs√£o de Recompra (XGBoost)**",
    "üó∫Ô∏è **3. Previs√£o de Pr√≥xima Rota (RandomForest)**"
])

# --- ABA 1: SEGMENTA√á√ÉO DE CLIENTES ---
with tab1:
    st.header("Segmenta√ß√£o de Clientes com RFM e K-Means")
    st.markdown("""
    Analisamos o hist√≥rico de compras dos clientes para agrup√°-los em segmentos distintos com base em tr√™s m√©tricas principais:
    - **Rec√™ncia (R):** Qu√£o recentemente compraram.
    - **Frequ√™ncia (F):** Com que frequ√™ncia compram.
    - **Valor Monet√°rio (M):** Quanto gastam.
    """)

    # An√°lise dos Clusters
    cluster_analysis = df_segmented.groupby('Cluster')[['Recency', 'Frequency', 'MonetaryValue']].mean().sort_values(by='MonetaryValue', ascending=False)
    
    # Adicionando Nomes e Descri√ß√µes das Personas
    personas = {
    2: {"nome": "üèÜ Super Clientes (Campe√µes)", "desc": "A elite absoluta. Frequ√™ncia e valor monet√°rio ordens de magnitude acima dos demais. Provavelmente ag√™ncias ou empresas. A√ß√£o: Tratamento VIP, gerente de contas dedicado."},
    3: {"nome": "‚ù§Ô∏è Clientes Fi√©is", "desc": "Compram muito recentemente, com alta frequ√™ncia e gastam bastante. S√£o a base de clientes recorrentes e engajados. A√ß√£o: Programas de fidelidade, ofertas exclusivas."},
    0: {"nome": "üí° Clientes Ocasionais", "desc": "Compram com baixa frequ√™ncia e n√£o o fazem h√° mais de um ano. Precisam de um incentivo para n√£o se tornarem inativos. A√ß√£o: Campanhas de reengajamento com descontos."},
    1: {"nome": "üëª Clientes Inativos (Churn)", "desc": "A √∫ltima compra foi h√° quase 6 anos. Clientes efetivamente perdidos, com baix√≠ssimo valor. A√ß√£o: Focar esfor√ßos de marketing nos outros grupos."}
}
    cluster_analysis['Persona'] = cluster_analysis.index.map(lambda x: personas.get(x, {"nome": "N√£o Definido"})['nome'])
    cluster_analysis['A√ß√£o Sugerida'] = cluster_analysis.index.map(lambda x: personas.get(x, {"desc": "A√ß√£o: N/A"})['desc'].split("A√ß√£o: ")[1])


    st.subheader("Resumo dos Segmentos (Personas)")
    st.dataframe(cluster_analysis[['Persona', 'Recency', 'Frequency', 'MonetaryValue', 'A√ß√£o Sugerida']].style.format({
        'Recency': '{:.0f} dias',
        'Frequency': '{:.1f} compras',
        'MonetaryValue': 'R$ {:,.2f}'
    }))

    # Visualiza√ß√µes Interativas
    st.subheader("Visualiza√ß√£o Interativa dos Clusters")
    col1, col2 = st.columns(2)

    with col1:
        # --- CORRE√á√ÉO APLICADA AQUI ---
        # Criar uma coluna 'MonetaryValueSize' para o tamanho, garantindo que seja >= 0
        df_segmented['MonetaryValueSize'] = df_segmented['MonetaryValue'].clip(lower=0)

        fig_scatter = px.scatter(
            df_segmented,
            x='Recency',
            y='Frequency',
            color='Cluster',
            size='MonetaryValueSize',  # Usando a nova coluna para o tamanho
            hover_name='fk_contact',
            hover_data={'MonetaryValue': True, 'MonetaryValueSize': False}, # Mostra o valor original no hover
            title='Vis√£o Geral dos Clusters (RFM)',
            labels={'Recency': 'Rec√™ncia (dias)', 'Frequency': 'Frequ√™ncia (compras)'},
            color_continuous_scale=px.colors.sequential.Viridis
        )
        # Oculta a legenda de tamanho, que agora √© apenas para visualiza√ß√£o
        fig_scatter.update_layout(showlegend=True)
        st.plotly_chart(fig_scatter, use_container_width=True)

    with col2:
        fig_bar = px.bar(
            cluster_analysis.sort_values('MonetaryValue'),
            x='MonetaryValue',
            y='Persona',
            orientation='h',
            color='Persona',
            title='Valor Monet√°rio M√©dio por Segmento',
            labels={'MonetaryValue': 'Valor M√©dio (R$)', 'Persona': 'Segmento'}
        )
        st.plotly_chart(fig_bar, use_container_width=True)

# --- ABA 3: PREVIS√ÉO DE PR√ìXIMA ROTA ---
with tab3:
    st.header("Previs√£o do Pr√≥ximo Trecho de Viagem")
    st.markdown("""
    O objetivo aqui √© prever qual ser√° a **pr√≥xima rota** que um cliente ir√° comprar. Comparamos um modelo simples (baseline) com um modelo avan√ßado de Machine Learning.
    """)

    # --- L√≥gica do Modelo (em cache para performance) ---
    @st.cache_resource
    def train_route_model(df):
        df_sorted = df.sort_values(by=['fk_contact', 'datetime_purchase'])
        df_sorted['last_route'] = df_sorted.groupby('fk_contact')['target_route'].shift(1)
        df_predict = df_sorted.dropna(subset=['last_route'])
        
        X = df_predict[['last_route']]
        y = df_predict['target_route']
        
        le = LabelEncoder()
        X['last_route_encoded'] = le.fit_transform(X['last_route'])
        X = X.drop('last_route', axis=1)
        
        model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)
        model.fit(X, y)
        return model, le

    rf_route_model, route_encoder = train_route_model(df_processed)

    st.subheader("Compara√ß√£o de Performance dos Modelos")
    col1, col2 = st.columns(2)
    with col1:
        st.metric(label="**Baseline (Prever a Rota Mais Frequente)**", value="24.02%")
    with col2:
        st.metric(label="**Modelo RandomForest (Prev√™ Top 50 Rotas)**", value="78.75%", delta="54.73%")
    st.success("O modelo RandomForest √© **3.3x mais preciso** que o baseline.")

    st.subheader("Teste o Modelo de Previs√£o de Rota")
    multi_purchase_clients = df_processed['fk_contact'].value_counts()[df_processed['fk_contact'].value_counts() > 1].index
    sample_client = st.selectbox("Selecione um cliente para testar:", options=multi_purchase_clients)
    
    if sample_client:
        # --- CORRE√á√ÉO (Parte 3): Esta l√≥gica agora funciona corretamente ---
        client_history = df_processed[df_processed['fk_contact'] == sample_client].sort_values('datetime_purchase')
        last_route_real = client_history['route'].iloc[-1]
        
        if len(client_history) > 1:
            last_route_for_prediction = client_history['target_route'].iloc[-2]
            
            last_route_encoded = route_encoder.transform([last_route_for_prediction])
            prediction = rf_route_model.predict([[last_route_encoded[0]]])
            
            st.write(f"**Hist√≥rico do Cliente:** A pen√∫ltima rota foi **{last_route_for_prediction}**.")
            st.write(f"‚û°Ô∏è **Previs√£o do Modelo para a Pr√≥xima Rota:** **{prediction[0]}**")
            st.write(f"üéØ **Rota Real da √öltima Viagem:** **{last_route_real}**")
            
            if prediction[0] == last_route_real or (prediction[0] == 'Outra' and last_route_real not in top_routes_global):
                st.success("O modelo acertou a previs√£o!")
            else:
                st.warning("O modelo n√£o acertou a previs√£o.")
        else:
            st.write("Este cliente tem apenas uma compra, n√£o √© poss√≠vel prever a pr√≥xima rota com base no hist√≥rico.")
       

# --- ABA 2: PREVIS√ÉO DE RECOMPRA ---
with tab2:
    st.header("Previs√£o de Recompra nos Pr√≥ximos 30 Dias")
    st.markdown("""
    Aqui, o desafio √© identificar quais clientes t√™m a maior probabilidade de realizar uma nova compra no pr√≥ximo m√™s.
    Constru√≠mos um modelo **XGBoost** que, apesar de uma precis√£o aparentemente baixa, oferece um grande valor de neg√≥cio.
    """)

    # --- L√≥gica do Modelo (em cache para performance) ---
    @st.cache_resource
    def train_repurchase_model(df):
        # 1. Janela de predi√ß√£o
        cutoff_date = df['datetime_purchase'].max() - pd.Timedelta(days=30)
        df_train = df[df['datetime_purchase'] < cutoff_date]
        df_target = df[df['datetime_purchase'] >= cutoff_date]
        snapshot_date_model = cutoff_date + pd.Timedelta(days=1)
        
        # 2. Features
        features_df = df_train.groupby('fk_contact').agg(
            Recency=('datetime_purchase', lambda date: (snapshot_date_model - date.max()).days),
            Frequency=('datetime_purchase', 'count'),
            MonetaryValue=('gmv_success', 'sum')
        ).reset_index()

        # 3. Alvo
        target_customers = df_target['fk_contact'].unique()
        features_df['will_buy_in_30_days'] = features_df['fk_contact'].isin(target_customers).astype(int)
        
        X = features_df[['Recency', 'Frequency', 'MonetaryValue']]
        y = features_df['will_buy_in_30_days']
        
        # 4. Par√¢metro de balanceamento
        scale_pos_weight = y.value_counts()[0] / y.value_counts()[1]
        
        # 5. Treinar modelo
        model = xgb.XGBClassifier(
            scale_pos_weight=scale_pos_weight, use_label_encoder=False, 
            eval_metric='logloss', random_state=42
        )
        model.fit(X, y)
        return model, X, y

    xgb_repurchase_model, X_repurchase, y_repurchase = train_repurchase_model(df_processed)
    
    # --- Exibi√ß√£o dos Resultados ---
    st.subheader("O Valor de Neg√≥cio do Modelo XGBoost")
    st.markdown("""
    Embora a **precis√£o** do modelo seja de **12%** (com limiar ajustado), isso representa um ganho enorme. Se a taxa de recompra natural √© de ~2.6%, nosso modelo √© **4.6x mais eficaz** em encontrar clientes propensos a comprar.
    """)
    
    col1, col2 = st.columns(2)
    with col1:
        st.info("**Perfil do Modelo (XGBoost com limiar ajustado para 0.6)**")
        st.markdown("- **Precis√£o (Precision): 12%**\n    - *De cada 100 clientes que o modelo aponta, 12 realmente compram.*")
        st.markdown("- **Alcance (Recall): 70%**\n    - *O modelo consegue encontrar 70% de todos os clientes que de fato recompraram.*")
        
    with col2:
        fig_lift = go.Figure(go.Indicator(
            mode = "gauge+number",
            value = 4.6,
            title = {'text': "Ganho de Efici√™ncia (Lift) vs. Abordagem Gen√©rica"},
            gauge = {'axis': {'range': [1, 10]}, 'bar': {'color': "green"}},
            domain = {'x': [0, 1], 'y': [0, 1]}
        ))
        st.plotly_chart(fig_lift, use_container_width=True)
    
    st.subheader("Estrat√©gia de Uso")
    st.success("""
    **Este modelo √© ideal para campanhas de marketing de baixo custo e grande escala (ex: e-mail marketing).** Ele nos permite focar em um grupo muito mais qualificado de clientes, maximizando o alcance e o retorno sobre o investimento.
    """)

st.sidebar.header("Sobre o Projeto")
st.sidebar.info("""
Este dashboard √© o resultado de uma an√°lise de dados completa para a ClickBus, cobrindo desde a segmenta√ß√£o de clientes at√© a cria√ß√£o de modelos preditivos avan√ßados.
- **Tecnologias:** Python, Pandas, Scikit-learn, XGBoost, Streamlit, Plotly.
- **Objetivo:** Transformar dados brutos em insights acion√°veis e ferramentas estrat√©gicas para o neg√≥cio.
""")